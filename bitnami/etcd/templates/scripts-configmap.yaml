{{- $replicaCount := int .Values.replicaCount }}
{{- $clientPort := int .Values.service.port }}
{{- $peerPort := int .Values.service.peerPort }}
{{- $etcdAuthOptions := include "etcd.authOptions" . }}
{{- $etcdFullname := include "common.names.fullname" . }}
{{- $releaseNamespace := .Release.Namespace }}
{{- $etcdHeadlessServiceName := printf "%s-headless" $etcdFullname }}
{{- $clusterDomain := .Values.clusterDomain }}
{{- $etcdPeerProtocol := include "etcd.peerProtocol" . }}
{{- $etcdClientProtocol := include "etcd.clientProtocol" . }}
{{- $initSnapshotPath := printf "/init-snapshot/%s" .Values.startFromSnapshot.snapshotFilename }}
{{- if and .Values.disasterRecovery.enabled .Values.startFromSnapshot.enabled (not .Values.disasterRecovery.pvc.existingClaim) }}
{{- $initSnapshotPath = printf "/snapshots/%s" .Values.startFromSnapshot.snapshotFilename }}
{{- end }}
{{- $snapshotHistoryLimit := .Values.disasterRecovery.cronjob.snapshotHistoryLimit }}
{{- $endpoints := list }}
{{- range $e, $i := until $replicaCount }}
{{- $endpoints = append $endpoints (printf "%s-%d.%s.%s.svc.%s:%d" $etcdFullname $i $etcdHeadlessServiceName $releaseNamespace $clusterDomain $clientPort) }}
{{- end }}
apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ printf "%s-scripts" (include "common.names.fullname" .) }}
  namespace: {{ .Release.Namespace }}
  labels: {{- include "common.labels.standard" . | nindent 4 }}
    {{- if .Values.commonLabels }}
    {{- include "common.tplvalues.render" ( dict "value" .Values.commonLabels "context" $ ) | nindent 4 }}
    {{- end }}
  {{- if .Values.commonAnnotations }}
  annotations: {{- include "common.tplvalues.render" ( dict "value" .Values.commonAnnotations "context" $ ) | nindent 4 }}
  {{- end }}
data:
  liblog.sh: |-
    #!/bin/bash
    #
    # Library for logging functions

    # Constants
    RESET='\033[0m'
    RED='\033[38;5;1m'
    GREEN='\033[38;5;2m'
    YELLOW='\033[38;5;3m'
    MAGENTA='\033[38;5;5m'
    CYAN='\033[38;5;6m'

    # Functions
    stderr_print() {
        local bool="${BITNAMI_QUIET:-false}"
        shopt -s nocasematch
        if ! [[ "$bool" = 1 || "$bool" =~ ^(yes|true)$ ]]; then
            printf "%b\\n" "${*}" >&2
        fi
    }
    log() {
        stderr_print "${CYAN}${MODULE:-} ${MAGENTA}$(date "+%T.%2N ")${RESET}${*}"
    }
    info() {
        log "${GREEN}INFO ${RESET} ==> ${*}"
    }
    warn() {
        log "${YELLOW}WARN ${RESET} ==> ${*}"
    }
    error() {
        log "${RED}ERROR${RESET} ==> ${*}"
    }
    debug() {
        local bool="${BITNAMI_DEBUG:-false}"
        shopt -s nocasematch
        if [[ "$bool" = 1 || "$bool" =~ ^(yes|true)$ ]]; then
            log "${MAGENTA}DEBUG${RESET} ==> ${*}"
        fi
    }
  libos.sh: |-
    #!/bin/bash
    #
    # Library for operating system actions

    # Load Generic Libraries
    . /scripts/liblog.sh

    # Functions
    debug_execute() {
        if ${BITNAMI_DEBUG:-false}; then
            "$@"
        else
            "$@" >/dev/null 2>&1
        fi
    }
  libetcd.sh: |-
    #!/bin/bash
    #
    # Bitnami etcd library

    # shellcheck disable=SC1091

    # Load Generic Libraries
    . /scripts/liblog.sh

    # Constants
    export ETCDCTL_ENDPOINTS={{ join "," $endpoints | quote }}
    export HOSTNAME="$(hostname -s)"
    export ROOT_PASSWORD="${ETCD_ROOT_PASSWORD:-}"
    [[ -n "${ETCD_ROOT_PASSWORD:-}" ]] && unset -v ETCD_ROOT_PASSWORD
    alias etcdctl="etcdctl {{ $etcdAuthOptions }}"

    # Functions
    ########################
    # Recalculate etcdctl endpoints
    ########################
    recalculate_endpoints() {
        local -r only_others=${1:-false}
        local -r this_endpoint="${ETCD_ADVERTISE_CLIENT_URLS#{{ $etcdClientProtocol }}://}"

        while ! etcdctl member list; do sleep 1; done
        if [[ $(etcdctl member list | wc -l) -ne $(wc -w <<< "${ETCDCTL_ENDPOINTS//,/ }") ]]; then
            export ETCDCTL_ENDPOINTS="$(etcdctl member list | awk -F "," '{print $5}' | tr -d ' ' | tr '\n' ',' | sed 's/,*$//g')"
        fi
        if [[ $only_others = true ]]; then
            export ETCDCTL_ENDPOINTS="$(tr -s , <<< ${ETCDCTL_ENDPOINTS//$this_endpoint/})"
        fi
        debug "New endpoints: $ETCDCTL_ENDPOINTS"
    }
    ########################
    # Store the member ID in a volume to be persisted
    ########################
    store_member_id() {
        while ! etcdctl member list; do sleep 1; done
        etcdctl member list | grep -w "$HOSTNAME" | awk -F "," '{ print $1}' > "${ETCD_DATA_DIR}/member_id"
        debug "Stored member ID: $(cat ${ETCD_DATA_DIR}/member_id)"
    }
    ########################
    # Configure etcd RBAC (do not confuse with K8s RBAC)
    ########################
    configure_rbac() {
        info "Configuring RBAC authentication"
        etcd &
        local etcd_pid=$!
        while ! etcdctl member list; do sleep 1; done
        echo "$ROOT_PASSWORD" | etcdctl user add root --interactive=false
        etcdctl auth enable
        kill "$etcd_pid"
        sleep 5
    }
    ########################
    # Check whether the member was successfully removed from the cluster
    ########################
    was_member_removed() {
        local return_value=0

        if (grep -sqE "^Member[[:space:]]+[a-z0-9]+\s+removed\s+from\s+cluster\s+[a-z0-9]+$" "$(dirname "$ETCD_DATA_DIR")/member_removal.log") || \
           ! ([[ -d "$ETCD_DATA_DIR/member/snap" ]] && [[ -f "$ETCD_DATA_DIR/member_id" ]]); then
            rm -rf ${ETCD_DATA_DIR}/*
        else
            return_value=1
        fi
        rm -f "$(dirname "$ETCD_DATA_DIR")/member_removal.log"
        return $return_value
    }
    ########################
    # Checks whether there was a disaster or not
    ########################
    is_disastrous_failure() {
        local -r -a endpoints_array=(${ETCDCTL_ENDPOINTS//,/ })
        local -r min_endpoints=$((({{ $replicaCount }} + 1)/2))
        local active_endpoints=0
        local return_value=1

        for e in "${endpoints_array[@]}"; do
            if [[ "$e" != "$ETCD_ADVERTISE_CLIENT_URLS" ]] && (unset -v ETCDCTL_ENDPOINTS; etcdctl endpoint health --endpoints="$e" >/dev/null 2>&1); then
                debug "$e endpoint is active"
                active_endpoints=$((active_endpoints + 1))
            fi
        done
{{- if .Values.disasterRecovery.enabled }}
        if [[ -f "/snapshots/.disaster_recovery" ]]; then
            if [[ $active_endpoints -eq $(({{ $replicaCount }} - 1)) ]]; then
                debug "Last member to recover from the disaster!"
                rm "/snapshots/.disaster_recovery"
            fi
            return_value=0
        else
            if [[ $active_endpoints -lt $min_endpoints ]]; then
                touch "/snapshots/.disaster_recovery"
                return_value=0
            fi
        fi
{{- else }}
        [[ $active_endpoints -lt $min_endpoints ]] && return_value=0
        return $return_value
{{- end }}
    }

  setup.sh: |-
    #!/bin/bash

    set -o errexit
    set -o pipefail
    set -o nounset
    shopt -s expand_aliases

    # Load Libraries
    . /scripts/liblog.sh
    . /scripts/libos.sh
    . /scripts/libetcd.sh

    if [[ ! -d "$ETCD_DATA_DIR" ]]; then
        info "There is no data from previous deployments"
{{- if gt $replicaCount 1 }}
        if [[ "$ETCD_INITIAL_CLUSTER_STATE" = "new" ]] && [[ $ETCD_INITIAL_CLUSTER = *"$ETCD_INITIAL_ADVERTISE_PEER_URLS"* ]]; then
            info "Bootstrapping a new cluster"
        else
            info "Adding new member to existing cluster"
            mkdir -p "$ETCD_DATA_DIR"
            recalculate_endpoints
            etcdctl member add "$HOSTNAME" --peer-urls="{{ $etcdPeerProtocol }}://${HOSTNAME}.{{ $etcdHeadlessServiceName }}.{{ .Release.Namespace }}.svc.{{ $clusterDomain }}:{{ $peerPort }}" | grep "^ETCD_" > "${ETCD_DATA_DIR}/new_member_envs"
            sed -ie "s/^/export /" "${ETCD_DATA_DIR}/new_member_envs"
            rm "${ETCD_DATA_DIR}/new_member_envse"
            debug "Loading env vars of existing cluster"
            . "${ETCD_DATA_DIR}/new_member_envs"
        fi
{{- end }}
{{- if .Values.startFromSnapshot.enabled }}
        if [[ -f "{{ $initSnapshotPath }}" ]]; then
            info "Initializing member by restoring etcd cluster from snapshot"
            debug_execute \etcdctl snapshot restore {{ $initSnapshotPath }} \
            {{- if gt $replicaCount 1 }}
              --name $ETCD_NAME \
              --initial-cluster $ETCD_INITIAL_CLUSTER \
              --initial-cluster-token $ETCD_INITIAL_CLUSTER_TOKEN \
              --initial-advertise-peer-urls $ETCD_INITIAL_ADVERTISE_PEER_URLS \
            {{- end }}
              --data-dir $ETCD_DATA_DIR
            debug_execute store_member_id &
        else
            error "There was no snapshot to perform data recovery!"
            exit 1
        fi
{{- else }}
        debug_execute store_member_id &
        # When there's more than one replica, we can assume there's one member
        # with hostname "{{ $etcdFullname }}-0" since a statefulset is used
        [[ -n "${ROOT_PASSWORD:-}" ]] && [[ "$HOSTNAME" = "{{ $etcdFullname }}-0" ]] && configure_rbac
{{- end }}
    else
        info "Detected data from previous deployments"
        if [[ $(stat -c "%a" "$ETCD_DATA_DIR") != *700 ]]; then
            debug "Setting data directory permissions to 700 in a recursive way (required in etcd >=3.4.10)"
            chmod -R 700 $ETCD_DATA_DIR
        fi
{{- if gt $replicaCount 1 }}
        if is_disastrous_failure; then
            warn "Cluster not responding!"
{{- if .Values.disasterRecovery.enabled }}
            latest_snapshot_file="$(find /snapshots/ -maxdepth 1 -type f -name 'db-*' | sort | tail -n 1)"
            if [[ "${latest_snapshot_file}" != "" ]]; then
                info "Restoring etcd cluster from snapshot"

                rm -rf $ETCD_DATA_DIR
                debug_execute \etcdctl snapshot restore "${latest_snapshot_file}" \
                  --name $ETCD_NAME \
                  --data-dir $ETCD_DATA_DIR \
                  --initial-cluster $ETCD_INITIAL_CLUSTER \
                  --initial-cluster-token $ETCD_INITIAL_CLUSTER_TOKEN \
                  --initial-advertise-peer-urls $ETCD_INITIAL_ADVERTISE_PEER_URLS
                debug_execute store_member_id &
            else
                error "There was no snapshot to perform data recovery!!"
                exit 1
            fi
{{- else }}
            warn "Disaster recovery is disabled, the cluster will try to recover on it's own"
{{- end }}
        elif was_member_removed; then
            info "Adding new member to existing cluster"
            recalculate_endpoints
            etcdctl member add "$HOSTNAME" --peer-urls="{{ $etcdPeerProtocol }}://${HOSTNAME}.{{ $etcdHeadlessServiceName }}.{{ .Release.Namespace }}.svc.{{ $clusterDomain }}:{{ $peerPort }}" | grep "^ETCD_" > "${ETCD_DATA_DIR}/new_member_envs"
            sed -ie "s/^/export /" "${ETCD_DATA_DIR}/new_member_envs"
            rm "${ETCD_DATA_DIR}/new_member_envse"
            debug "Loading env vars of existing cluster"
            . "${ETCD_DATA_DIR}/new_member_envs"
            debug_execute store_member_id &
        else
            info "Updating member in existing cluster"
            export ETCD_INITIAL_CLUSTER_STATE=existing
            recalculate_endpoints true
            etcdctl member update "$(cat "$ETCD_DATA_DIR/member_id")" --peer-urls="{{ $etcdPeerProtocol }}://${HOSTNAME}.{{ $etcdHeadlessServiceName }}.{{ .Release.Namespace }}.svc.{{ $clusterDomain }}:{{ $peerPort }}"
        fi
{{- end }}
    fi
    {{- if .Values.configFileConfigMap }}
    exec etcd --config-file /opt/bitnami/etcd/conf/etcd.conf.yml
    {{- else }}
    exec etcd
    {{- end }}

  prestop-hook.sh: |-
    #!/bin/bash

    set -o errexit
    set -o pipefail
    set -o nounset
    shopt -s expand_aliases

    # Load Generic Libraries
    . /scripts/libetcd.sh

    recalculate_endpoints true
    etcdctl member remove --debug=true "$(cat "${ETCD_DATA_DIR}/member_id")" > "$(dirname "$ETCD_DATA_DIR")/member_removal.log"

  probes.sh: |-
    #!/bin/bash

    set -o errexit
    set -o pipefail
    set -o nounset
    shopt -s expand_aliases

    # Load Generic Libraries
    . /scripts/liblog.sh
    . /scripts/libetcd.sh

    debug "Probing etcd cluster"
    debug 'Probe command: "etcdctl endpoint health"'
    # It's important to unset ETCDCTL_ENDPOINTS to avoid checking every endpoint 
    if (unset -v ETCDCTL_ENDPOINTS; etcdctl endpoint health --endpoints="${ETCD_ADVERTISE_CLIENT_URLS#{{ $etcdClientProtocol }}://}"); then
        exit 0
    else
        error "Unhealthy endpoint!"
        exit 1
    fi

{{- if .Values.disasterRecovery.enabled }}
  save-snapshot.sh: |-
    #!/bin/bash

    set -o errexit
    set -o pipefail
    set -o nounset
    shopt -s expand_aliases

    # Load Generic Libraries
    . /scripts/liblog.sh
    . /scripts/libetcd.sh

    mkdir -p "/snapshots"
    recalculate_endpoints
    endpoints_array=(${ETCDCTL_ENDPOINTS//,/ })

    for e in "${endpoints_array[@]}"; do
        debug "Using endpoint $e"
        if (unset -v ETCDCTL_ENDPOINTS; etcdctl endpoint health --endpoints=${e}); then
            info "Snapshotting the keyspace"
            current_time="$(date -u "+%Y-%m-%d_%H-%M")"
            unset -v ETCDCTL_ENDPOINTS; etcdctl snapshot save "/snapshots/db-${current_time}" --endpoints=${e}
            find /snapshots/ -maxdepth 1 -type f -name 'db-*' \! -name "db-${current_time}" \
                | sort -r \
                | tail -n+$((1 + {{ $snapshotHistoryLimit }})) \
                | xargs rm -f
            exit 0
        else
            warn "etcd endpoint ${ETCDCTL_ENDPOINTS} not healthy. Trying a different endpoint"
        fi
    done

    error "all etcd endpoints are unhealthy!"
    exit 1

{{- end }}
